
# AI Routing Service Environment Configuration

# Service Configuration
SERVICE_NAME=ai-routing-service
PORT=9002
NODE_ENV=development

# Database
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/ai_employee_platform

# Redis for Caching
REDIS_URL=redis://redis:6379
CACHE_TTL=3600

# AI Provider API Keys
OPENAI_API_KEY=your_openai_api_key
OPENAI_ORG_ID=your_openai_org_id
CLAUDE_API_KEY=your_claude_api_key
GEMINI_API_KEY=your_gemini_api_key
COHERE_API_KEY=your_cohere_api_key

# Local LLM Configuration (Optional)
OLLAMA_HOST=http://localhost:11434
OLLAMA_ENABLED=false

# Routing Configuration
DEFAULT_MODEL=gpt-3.5-turbo
FALLBACK_MODEL=gpt-3.5-turbo
MAX_RETRIES=3
RETRY_DELAY=1000

# Load Balancing
LOAD_BALANCING_STRATEGY=round_robin
HEALTH_CHECK_INTERVAL=30000

# Cost Optimization
COST_OPTIMIZATION_ENABLED=true
COST_THRESHOLD_WARNING=0.80
COST_THRESHOLD_CRITICAL=0.95

# Rate Limiting per Provider
OPENAI_RATE_LIMIT=60
CLAUDE_RATE_LIMIT=50
GEMINI_RATE_LIMIT=60

# Request Timeout
REQUEST_TIMEOUT=30000
PROVIDER_TIMEOUT=25000

# Logging
LOG_LEVEL=info
LOG_FORMAT=combined
LOG_AI_REQUESTS=true

# Monitoring
HEALTH_CHECK_ENABLED=true
METRICS_ENABLED=true

# Model Capability Mapping
CAPABILITY_CACHE_TTL=7200
MODEL_REFRESH_INTERVAL=3600000

